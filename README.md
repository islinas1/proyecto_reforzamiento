
# ğŸ§  **RatÃ³n vs Zorro â€“ IA con Aprendizaje por Refuerzo**

### *Proyecto acadÃ©mico de Inteligencia Artificial â€” SARSA / Q-Learning*

---

## ğŸ“Œ **DescripciÃ³n del Proyecto**

Este proyecto implementa un videojuego interactivo donde:

* ğŸ­ **El jugador controla un ratÃ³n**
* ğŸ¦Š **Un zorro controlado por IA intenta atraparlo**
* ğŸ§  La IA combina **Aprendizaje por Refuerzo (SARSA o Q-Learning)** con una arquitectura de control inspirada en el **"Director AI" de Alien: Isolation**.

El objetivo es estudiar cÃ³mo tÃ©cnicas modernas de IA pueden generar **comportamientos agresivos, adaptativos e inteligentes** dentro de un entorno dinÃ¡mico (laberintos).

El sistema aprende continuamente mediante:

* Recompensas
* Castigos
* Vecindarios del estado
* Modos de comportamiento del Director IA

AdemÃ¡s, la IA **guarda su aprendizaje** usando pickle, manteniendo su progreso entre partidas.

---

## ğŸ® **CaracterÃ­sticas principales**

### âœ” Tres niveles de laberintos fijos pero distintos

El jugador selecciona el nivel antes de empezar.

### âœ” IA con dos capas:

#### **1. Aprendizaje por Refuerzo**

* SARSA (on-policy)
* Q-learning (off-policy)
* Uso de la ecuaciÃ³n de Bellman
* Proceso de DecisiÃ³n de Markov (MDP)

#### **2. Director IA (Arquitectura inteligente)**

* Modos de comportamiento:

  * CAZANDO
  * ACECHANDO
  * BUSCANDO
  * RASTRO RECIENTE
  * ZONA CALIENTE
  * EXPLORANDO
* Recuerdo de Ãºltima posiciÃ³n vista
* Heatmap del movimiento del ratÃ³n
* ModulaciÃ³n del epsilon dinÃ¡mico

### âœ” Registro del aprendizaje y comportamiento

El sistema almacena:

* Q-table (`.pkl`)
* Recompensa por paso (`aprendizaje.csv`)
* Tiempos por partida (`registroTiempo.txt`)

### âœ” GrÃ¡ficas incluidas

* Recompensa media mÃ³vil
* Castigo acumulado
* Curva de aprendizaje (evoluciÃ³n del zorro)
* Tiempo promedio en atrapar al ratÃ³n
* ComparaciÃ³n entre niveles

---

## ğŸ—‚ **Estructura del Proyecto**

```
proyecto-reforzamiento/
â”‚
â”œâ”€â”€ main.py               # Punto de entrada del juego
â”œâ”€â”€ game.py               # LÃ³gica principal del juego (loop, niveles, estados)
â”œâ”€â”€ rl_agent.py           # Agente del zorro (SARSA / Q-Learning)
â”œâ”€â”€ director_ia.py        # Sistema inteligente de comportamiento
â”œâ”€â”€ laberinto.py          # DefiniciÃ³n de los tres niveles de laberinto
â”œâ”€â”€ config.py             # HiperparÃ¡metros y rutas del sistema
â”‚
â”œâ”€â”€ analisis/
â”‚   â”œâ”€â”€ graficas.py       # GeneraciÃ³n de mÃ©tricas y anÃ¡lisis
â”‚   â””â”€â”€ resultados/       # (Opcional) imÃ¡genes generadas
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ qtable.pkl        # Memoria persistente del zorro (autogenerada)
â”‚
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ aprendizaje.csv   # Recompensa por paso
â”‚   â””â”€â”€ registro.txt      # Movimientos y recompensas
â”‚
â”œâ”€â”€ informe/              # Carpeta ignorada por Git (.gitignore)
â”‚
â””â”€â”€ README.md             # Este archivo
```

---

## âš™ï¸ **TecnologÃ­as utilizadas**

* **Python 3.10+**
* **Pygame** â€” motor del juego
* **Pickle** â€” persistencia de la Q-table
* **Numpy / MatemÃ¡ticas bÃ¡sicas** â€” cÃ¡lculos de distancia y estados
* **Aprendizaje por Refuerzo** â€” SARSA o Q-learning seleccionable
* **Arquitectura IA tipo â€œDirectorâ€** inspirada en videojuegos AAA

---

## ğŸš€ **InstalaciÃ³n y EjecuciÃ³n**

### 1. Clonar el repositorio:

```bash
git clone https://github.com/tu_usuario/proyecto-reforzamiento.git
cd proyecto-reforzamiento
```

### 2. Crear entorno virtual (opcional pero recomendado):

```bash
python -m venv .venv
.\.venv\Scripts\activate  # Windows
```

### 3. Instalar dependencias:

```bash
pip install pygame numpy matplotlib
```

### 4. Ejecutar el juego:

```bash
python main.py
```

---

## ğŸ“Š **Resultados y anÃ¡lisis**

El sistema registra todo el proceso de aprendizaje.
Las grÃ¡ficas muestran:

* Al inicio, recompensas negativas â†’ exploraciÃ³n y errores.
* Luego, curva ascendente â†’ el zorro aprende rutas Ã³ptimas.
* DisminuciÃ³n de castigos â†’ mejor toma de decisiones.
* Tiempos de captura mÃ¡s cortos con entrenamiento prolongado.
* Diferencias de desempeÃ±o entre los 3 niveles.

Estas mÃ©tricas confirman:

> **La IA no solo funciona, sino que realmente aprende y mejora con la experiencia.**

---

## ğŸ“ **Objetivo del proyecto**

Demostrar cÃ³mo integrar:

1. **Modelos de Aprendizaje por Refuerzo**
2. **Arquitectura inteligente de control (Director IA)**
3. **Entornos interactivos en tiempo real (videojuego)**

para producir agentes capaces de comportamientos **adaptativos, agresivos e inteligentes**, similares a juegos modernos.

---

## ğŸ **ConclusiÃ³n**

Este proyecto combina tÃ©cnicas fundamentales y avanzadas de inteligencia artificial para crear un agente que:

* Aprende del entorno
* Evoluciona su estrategia
* Modifica su comportamiento segÃºn contexto
* Mantiene memoria de entrenamiento
* Se adapta al jugador en tiempo real

Es un ejemplo sÃ³lido y aplicable de IA moderna dentro de un entorno lÃºdico, demostrando cÃ³mo conceptos teÃ³ricos pueden implementarse en sistemas funcionales.

---

## ğŸ‘¤ **Autor**

**Ian Ezequiel Salinas Condori**
Estudiante de InformÃ¡tica â€“ UMSA
Proyecto de Inteligencia Artificial / Aprendizaje por Refuerzo
